{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db92277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/mendez_juan_tp_dt\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Installing collected packages: my_project\n",
      "  Attempting uninstall: my_project\n",
      "    Found existing installation: my_project 0.1\n",
      "    Uninstalling my_project-0.1:\n",
      "      Successfully uninstalled my_project-0.1\n",
      "  Running setup.py develop for my_project\n",
      "Successfully installed my_project-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1148764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# === CONFIGURACIÓN DEL DATASET ===\n",
    "# Cambiar aquí para elegir Netflix o Goodreads\n",
    "DATASET = 'netflix'  # o 'goodreads'\n",
    "\n",
    "if DATASET == 'netflix':\n",
    "    NUM_ITEMS = 752\n",
    "    train_path = 'data/train/netflix8_train.df'\n",
    "    test_path = 'data/test_users/netflix8_test.json'\n",
    "else:\n",
    "    NUM_ITEMS = 472\n",
    "    train_path = 'data/train/goodreads8_train.df'\n",
    "    test_path = 'data/test_users/goodreads8_test.json'\n",
    "\n",
    "NUM_GROUPS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b7bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Cargando datos...\n",
      "Train users: 16000\n",
      "Test users: 1600\n",
      "Num items: 752\n"
     ]
    }
   ],
   "source": [
    "# === 1. CARGAR DATOS ===\n",
    "print(\"\\n[1/5] Cargando datos...\")\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "\n",
    "import json\n",
    "with open(test_path, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Train users: {len(df_train)}\")\n",
    "print(f\"Test users: {len(test_data)}\")\n",
    "print(f\"Num items: {NUM_ITEMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a48563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] Creando dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|██████████| 16000/16000 [00:01<00:00, 12762.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.data.preprocessing import create_dt_dataset, DTDataset\n",
    "\n",
    "# === 2. CREAR DATASET ===\n",
    "print(\"\\n[2/5] Creando dataset...\")\n",
    "\n",
    "max_len = 20  # longitud máxima de secuencia\n",
    "train_data = create_dt_dataset(df_train, max_len=max_len)\n",
    "train_dataset = DTDataset(train_data, max_len=max_len)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be75fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] Creando modelo...\n",
      "Total parameters: 803,056\n"
     ]
    }
   ],
   "source": [
    "from src.models.decision_transformer import DecisionTransformerHF\n",
    "\n",
    "# === 3. CREAR MODELO ===\n",
    "print(\"\\n[3/5] Creando modelo...\")\n",
    "\n",
    "model = DecisionTransformerHF(\n",
    "    num_items=NUM_ITEMS,\n",
    "    num_groups=NUM_GROUPS,\n",
    "    hidden_dim=128,\n",
    "    n_layers=3,\n",
    "    n_heads=4,\n",
    "    max_seq_len=max_len,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7532b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/250 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 1/10:   0%|          | 0/250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2487286516.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[4/5] Entrenando modelo...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model = train_decision_transformer_hf(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/mendez_juan_tp_dt/src/training/trainer.py\u001b[0m in \u001b[0;36mtrain_decision_transformer_hf\u001b[0;34m(model, train_loader, num_epochs, learning_rate, weight_decay, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             action_logits = model(\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/mendez_juan_tp_dt/src/models/decision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, states, actions, rtgs, timesteps, groups, attention_mask)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Crear secuencia alternada: group_0, state_0, action_0, rtg_0, group_1, ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Shape final: (batch, seq_len * 4, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         stacked_inputs = torch.stack(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mgroup_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtg_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         ).reshape(batch_size, seq_len * 4, self.hidden_dim)\n",
      "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from src.training.trainer import train_decision_transformer_hf\n",
    "\n",
    "# === 4. ENTRENAR ===\n",
    "print(\"\\n[4/5] Entrenando modelo...\")\n",
    "\n",
    "model = train_decision_transformer_hf(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=10,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Guardar modelo\n",
    "torch.save(model.state_dict(), f'decision_transformer_hf_{DATASET}.pt')\n",
    "print(f\"Modelo guardado: decision_transformer_hf_{DATASET}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
